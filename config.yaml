# Configuration for ML Compiler Benchmark

benchmark:
  warmup_iterations: 10      # Iterations to skip (GPU warmup, JIT compilation)
  measured_iterations: 100   # Iterations to measure and report

model:
  name: resnet50
  input_shape: [3, 224, 224]  # ImageNet standard (C, H, W) for vision models
  batch_sizes: [1, 32]        # Single image vs batched
  precision: fp32             # fp32, fp16, or int8

compilers:
  - pytorch_eager      # Baseline (no compilation)
  - torchscript        # TorchScript JIT compiler (works on P100!)
  - onnx_runtime       # ONNX Runtime with GPU support
  # - tvm               # Apache TVM compiler
  # - tvm_autotuned     # TVM with autotuning (slower compilation, better performance)
  # - tensorrt          # TensorRT (FP32, may have limitations on P100)
  # - tensorrt_fp16     # TensorRT with FP16 precision

output:
  format: csv
  save_path: results/
